{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "11rUjwwA9zqv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbV8Ifzxsvh9",
        "outputId": "ac46a652-5bf3-4654-cc18-862dfe12b2da"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/Colab Notebooks/cleaned_training_data.csv'"
      ],
      "metadata": {
        "id": "mHrYj-yXsvkh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "gexsJcbYtEA3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "PKT6LEJytFLL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "IrogZzL_Vzhe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(file_path,  header=0)"
      ],
      "metadata": {
        "id": "REP43TAiZOBn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Subsample the majority class\n",
        "# data_majority = data[data['bad_flag'] == 0]\n",
        "# data_minority = data[data['bad_flag'] == 1]\n",
        "\n",
        "# # Downsample majority class\n",
        "# data_majority_downsampled = data_majority.sample(2*len(data_minority), random_state=42)\n",
        "\n",
        "# data_balanced = pd.concat([data_majority_downsampled, data_minority])\n",
        "\n",
        "# # Shuffle the balanced dataset\n",
        "# data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Nf3u2zB4v4CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjIjsh9_JoIt",
        "outputId": "0eb6ccf8-5413-4f12-80ef-f736bbf57d9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['term', 'int_rate', 'emp_length', 'annual_inc', 'percent_bc_gt_75',\n",
              "       'dti', 'inq_last_6mths', 'mths_since_recent_inq', 'total_bc_limit',\n",
              "       'tot_cur_bal', 'internal_score', 'bad_flag', 'purpose_car',\n",
              "       'purpose_credit_card', 'purpose_debt_consolidation',\n",
              "       'purpose_home_improvement', 'purpose_house', 'purpose_major_purchase',\n",
              "       'purpose_medical', 'purpose_moving', 'purpose_other',\n",
              "       'purpose_renewable_energy', 'purpose_small_business',\n",
              "       'purpose_vacation', 'purpose_wedding', 'home_ownership_MORTGAGE',\n",
              "       'home_ownership_OTHER', 'home_ownership_OWN', 'home_ownership_RENT'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['bad_flag'].astype(float)\n",
        "X = data.drop(columns=['bad_flag'])"
      ],
      "metadata": {
        "id": "lBkMZSGQwhj8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.10, random_state=1000\n",
        ")"
      ],
      "metadata": {
        "id": "pM3O-ebSzBT-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t, X_val, y_t, y_val = train_test_split(\n",
        "    X_train, y_train, stratify=y_train, test_size=0.20, random_state=1000\n",
        ")"
      ],
      "metadata": {
        "id": "raaAFJ2vzMws"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_t.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9oJANiOBdK_",
        "outputId": "16ecda21-48b3-4038-95c4-d4eea8bb90b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bad_flag\n",
            "0.0    126956\n",
            "1.0      9452\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_val.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKGaQYJSBgsJ",
        "outputId": "c85d27ee-8233-4923-e39e-0a39d48b59b2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bad_flag\n",
            "0.0    31740\n",
            "1.0     2363\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(sampling_strategy=0.1, random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_t, y_t)"
      ],
      "metadata": {
        "id": "O8nXb8ZBirnn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Define the pipeline: SMOTE for oversampling + RandomUnderSampler for undersampling\n",
        "sampling_strategy_smote = 1.  # Increase minority to 50% of majority\n",
        "sampling_strategy_under = 1. # Reduce majority to 60% of original\n",
        "\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy_smote, random_state=42)\n",
        "under_sampler = RandomUnderSampler(sampling_strategy=sampling_strategy_under, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('smote', smote),\n",
        "    ('under', under_sampler)\n",
        "])\n",
        "\n",
        "# Resample the training data\n",
        "# X_train_smote, y_train_smote = pipeline.fit_resample(X_t, y_t)\n",
        "X_train_smote, y_train_smote = X_t, y_t"
      ],
      "metadata": {
        "id": "Fy3btBrnJRsT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numer = ['term', 'int_rate', 'emp_length', 'annual_inc', 'percent_bc_gt_75',\n",
        "        'dti', 'inq_last_6mths', 'mths_since_recent_inq',\n",
        "       'total_bc_limit', 'tot_cur_bal', 'internal_score']\n",
        "dummy = X_train.columns.difference(numer)"
      ],
      "metadata": {
        "id": "wxxxO4ZgJ3XO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_num_scaled = scaler.fit_transform(X_train_smote[numer])\n",
        "X_val_num_scaled = scaler.transform(X_val[numer])"
      ],
      "metadata": {
        "id": "VYJSAUuYJ8X-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled1 = pd.DataFrame(X_train_num_scaled, columns=numer, index=X_train_smote.index)\n",
        "X_train_scaled = pd.concat([X_train_scaled1, X_train_smote[dummy]], axis=1)\n",
        "\n",
        "X_val_scaled1 = pd.DataFrame(X_val_num_scaled, columns=numer, index=X_val.index)\n",
        "X_val_scaled = pd.concat([X_val_scaled1, X_val[dummy]], axis=1)"
      ],
      "metadata": {
        "id": "AK2_9wEQKL3y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(y_train_smote.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKQic98avjby",
        "outputId": "338a067a-5772-46c6-c964-5145d3b33ec7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bad_flag\n",
            "0.0    126956\n",
            "1.0      9452\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_smote.values, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "rRK60e4htFQ1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_val_tensor.size(), y_val_tensor.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXwh2YEFCY8L",
        "outputId": "edbfa677-cf8f-4a27-bd9a-cc1c14c58481"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([34103, 28]) torch.Size([34103])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tensor.shape, y_train_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfJDwl-DCI0C",
        "outputId": "0685818d-ee7e-4f31-e5ee-6fb274885115"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([136408, 28]) torch.Size([136408])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3,  output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=0.2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(p=0.3)\n",
        "        self.fc4 = nn.Linear(hidden_size3, output_size)\n",
        "        # self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc4(x)\n",
        "        # x = self.relu4(x)\n",
        "        # x = self.fc5(x)\n",
        "        # x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Model configuration\n",
        "input_size = X_train_tensor.shape[1]\n",
        "print(input_size)\n",
        "hidden_size1 = 64  # Configurable\n",
        "hidden_size2 = 256\n",
        "hidden_size3 = 64\n",
        "output_size = 1\n",
        "\n",
        "# Instantiate the model\n",
        "model = NeuralNet(input_size, hidden_size1, hidden_size2, hidden_size3, output_size)"
      ],
      "metadata": {
        "id": "-9XeZuojtFTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e89836e-c672-40e5-9d17-344a381ed498"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        # Xavier (Glorot) initialization for weights\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        # Initialize biases to zero\n",
        "        nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "WmMvSJyKnR2-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCGN_oqvnT74",
        "outputId": "0885bd56-ba94-438c-95fc-4bd987d5d895"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (fc1): Linear(in_features=28, out_features=64, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=64, out_features=256, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (relu3): ReLU()\n",
              "  (dropout2): Dropout(p=0.3, inplace=False)\n",
              "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training loop\n",
        "epochs = 200  # Configurable\n",
        "batch_size = 32\n",
        "clip_value = 1.0\n",
        "# Loss function and optimizer\n",
        "# criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
        "pos_weight = torch.tensor([126956 / 9452], dtype=torch.float)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # Binary Cross-Entropy Loss\n",
        "# criterion = FocalLoss(alpha=0.25, gamma=2.0, reduction='mean')\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "J4vQsWslL1SL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e71b5bb-75e0-4b92-cdd0-c66ece9207ce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 10  # Number of epochs with no improvement to wait\n",
        "# best_val_loss = float(\"inf\")\n",
        "early_stop_counter = 0"
      ],
      "metadata": {
        "id": "KFj-f6bHnkCn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "best_threshold = 0.5\n",
        "best_f1_score = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for i in range(0, len(X_train_tensor), batch_size):\n",
        "        # Get mini-batch\n",
        "        X_batch = X_train_tensor[i:i+batch_size]\n",
        "        y_batch = y_train_tensor[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch).squeeze(dim = -1)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        total_loss += loss.item()\n",
        "        # print(\"Model output shape:\", outputs.shape)\n",
        "        # print(\"Target shape:\", y_batch.shape)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        train_outputs = model(X_train_tensor).squeeze()\n",
        "        train_predictions = (train_outputs > 0.5).float()\n",
        "        train_accuracy = accuracy_score(y_train_tensor.numpy(), train_predictions.numpy())\n",
        "        train_f1 = f1_score(y_train_tensor.numpy(), train_predictions.numpy())\n",
        "        train_recall = recall_score(y_train_tensor.numpy(), train_predictions.numpy())\n",
        "        train_precision = precision_score(y_train_tensor.numpy(), train_predictions.numpy())\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val_tensor).squeeze()\n",
        "        val_loss = criterion(val_outputs, y_val_tensor)\n",
        "\n",
        "        # # Generate probabilities for validation\n",
        "        val_probabilities = torch.sigmoid(val_outputs).numpy()\n",
        "\n",
        "        # Search for the best threshold to maximize F1-score\n",
        "        thresholds = np.arange(0.1, 0.9, 0.01)\n",
        "        for threshold in thresholds:\n",
        "            val_predictions = (val_probabilities > threshold).astype(int)\n",
        "            current_f1 = f1_score(y_val_tensor.numpy(), val_predictions)\n",
        "\n",
        "            if current_f1 > best_f1_score:\n",
        "                best_f1_score = current_f1\n",
        "                best_threshold = threshold\n",
        "\n",
        "        # Apply the best threshold for current evaluation\n",
        "        val_predictions = (val_probabilities > best_threshold).astype(int)\n",
        "        val_accuracy = accuracy_score(y_val_tensor.numpy(), val_predictions)\n",
        "        val_f1 = f1_score(y_val_tensor.numpy(), val_predictions)\n",
        "        val_recall = recall_score(y_val_tensor.numpy(), val_predictions)\n",
        "        val_precision = precision_score(y_val_tensor.numpy(), val_predictions)\n",
        "    scheduler.step(val_f1)\n",
        "    # Log epoch results\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "          f\"Loss: {total_loss / len(X_train_tensor):.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Train F1: {train_f1:.4f}, Train Recall: {train_recall:.4f}, Train Precision: {train_precision:.4f}, \"\n",
        "          f\"Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}, \"\n",
        "          f\"Val F1: {val_f1:.4f}, Val Recall: {val_recall:.4f}, Val Precision: {val_precision:.4f}, \"\n",
        "          f\"Best Threshold: {best_threshold:.2f}\")\n",
        "\n",
        "    if val_f1 >= best_f1_score:\n",
        "        best_f1_score = val_f1\n",
        "        torch.save(model.state_dict(), \"/content/drive/My Drive/Colab Notebooks/neural_net_model.pth\")\n",
        "        print(f\"Best model saved with F1-score: {val_f1:.4f}\")\n",
        "        early_stop_counter = 0  # Reset early stopping counter\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "    # print(val_f1, best_f1_score, early_stop_counter)\n",
        "    # Check early stopping condition\n",
        "    if early_stop_counter >= patience:\n",
        "        print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
        "        break\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), \"/content/drive/My Drive/Colab Notebooks/neural_net_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu2WiWOWKjty",
        "outputId": "a0a96f08-fa76-42f2-f355-048d8d1791d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Loss: 0.0396, Train Accuracy: 0.8641, Train F1: 0.1790, Train Recall: 0.2137, Train Precision: 0.1539, Val Loss: 1.2047, Val Accuracy: 0.7628, Val F1: 0.2021, Val Recall: 0.4333, Val Precision: 0.1317, Best Threshold: 0.56\n",
            "Best model saved with F1-score: 0.2021\n",
            "Epoch 2/200, Loss: 0.0393, Train Accuracy: 0.8574, Train F1: 0.1917, Train Recall: 0.2440, Train Precision: 0.1579, Val Loss: 1.2077, Val Accuracy: 0.7697, Val F1: 0.2068, Val Recall: 0.4333, Val Precision: 0.1358, Best Threshold: 0.56\n",
            "Best model saved with F1-score: 0.2068\n",
            "Epoch 3/200, Loss: 0.0397, Train Accuracy: 0.8647, Train F1: 0.1944, Train Recall: 0.2355, Train Precision: 0.1655, Val Loss: 1.2223, Val Accuracy: 0.7862, Val F1: 0.2105, Val Recall: 0.4113, Val Precision: 0.1414, Best Threshold: 0.56\n",
            "Best model saved with F1-score: 0.2105\n",
            "Epoch 4/200, Loss: 0.0401, Train Accuracy: 0.8699, Train F1: 0.1965, Train Recall: 0.2296, Train Precision: 0.1717, Val Loss: 1.2225, Val Accuracy: 0.7781, Val F1: 0.2082, Val Recall: 0.4211, Val Precision: 0.1383, Best Threshold: 0.56\n",
            "Epoch 5/200, Loss: 0.0402, Train Accuracy: 0.8595, Train F1: 0.2040, Train Recall: 0.2598, Train Precision: 0.1679, Val Loss: 1.2287, Val Accuracy: 0.7721, Val F1: 0.2087, Val Recall: 0.4338, Val Precision: 0.1374, Best Threshold: 0.56\n",
            "Epoch 6/200, Loss: 0.0402, Train Accuracy: 0.8644, Train F1: 0.2061, Train Recall: 0.2539, Train Precision: 0.1734, Val Loss: 1.2242, Val Accuracy: 0.7890, Val F1: 0.2127, Val Recall: 0.4113, Val Precision: 0.1434, Best Threshold: 0.58\n",
            "Best model saved with F1-score: 0.2127\n",
            "Epoch 7/200, Loss: 0.0402, Train Accuracy: 0.8605, Train F1: 0.2075, Train Recall: 0.2635, Train Precision: 0.1711, Val Loss: 1.2310, Val Accuracy: 0.7958, Val F1: 0.2121, Val Recall: 0.3965, Val Precision: 0.1447, Best Threshold: 0.58\n",
            "Epoch 8/200, Loss: 0.0403, Train Accuracy: 0.8564, Train F1: 0.2114, Train Recall: 0.2777, Train Precision: 0.1706, Val Loss: 1.2239, Val Accuracy: 0.7733, Val F1: 0.2136, Val Recall: 0.4444, Val Precision: 0.1406, Best Threshold: 0.56\n",
            "Best model saved with F1-score: 0.2136\n",
            "Epoch 9/200, Loss: 0.0404, Train Accuracy: 0.8581, Train F1: 0.2128, Train Recall: 0.2769, Train Precision: 0.1728, Val Loss: 1.2254, Val Accuracy: 0.7783, Val F1: 0.2090, Val Recall: 0.4228, Val Precision: 0.1388, Best Threshold: 0.56\n",
            "Epoch 10/200, Loss: 0.0403, Train Accuracy: 0.8505, Train F1: 0.2181, Train Recall: 0.3010, Train Precision: 0.1710, Val Loss: 1.2277, Val Accuracy: 0.7654, Val F1: 0.2078, Val Recall: 0.4439, Val Precision: 0.1356, Best Threshold: 0.56\n",
            "Epoch 11/200, Loss: 0.0403, Train Accuracy: 0.8555, Train F1: 0.2208, Train Recall: 0.2956, Train Precision: 0.1763, Val Loss: 1.2346, Val Accuracy: 0.7798, Val F1: 0.2081, Val Recall: 0.4177, Val Precision: 0.1386, Best Threshold: 0.56\n",
            "Epoch 12/200, Loss: 0.0401, Train Accuracy: 0.8541, Train F1: 0.2189, Train Recall: 0.2950, Train Precision: 0.1740, Val Loss: 1.2480, Val Accuracy: 0.7771, Val F1: 0.2069, Val Recall: 0.4198, Val Precision: 0.1373, Best Threshold: 0.56\n",
            "Epoch 13/200, Loss: 0.0402, Train Accuracy: 0.8563, Train F1: 0.2216, Train Recall: 0.2951, Train Precision: 0.1774, Val Loss: 1.2548, Val Accuracy: 0.7823, Val F1: 0.2041, Val Recall: 0.4029, Val Precision: 0.1367, Best Threshold: 0.56\n",
            "Epoch 14/200, Loss: 0.0400, Train Accuracy: 0.8561, Train F1: 0.2242, Train Recall: 0.3001, Train Precision: 0.1789, Val Loss: 1.2375, Val Accuracy: 0.7786, Val F1: 0.2071, Val Recall: 0.4173, Val Precision: 0.1377, Best Threshold: 0.56\n",
            "Epoch 15/200, Loss: 0.0394, Train Accuracy: 0.8531, Train F1: 0.2308, Train Recall: 0.3180, Train Precision: 0.1811, Val Loss: 1.3232, Val Accuracy: 0.7961, Val F1: 0.2066, Val Recall: 0.3830, Val Precision: 0.1414, Best Threshold: 0.56\n",
            "Epoch 16/200, Loss: 0.0390, Train Accuracy: 0.8563, Train F1: 0.2314, Train Recall: 0.3121, Train Precision: 0.1838, Val Loss: 1.3251, Val Accuracy: 0.8044, Val F1: 0.2045, Val Recall: 0.3627, Val Precision: 0.1424, Best Threshold: 0.56\n",
            "Epoch 17/200, Loss: 0.0388, Train Accuracy: 0.8622, Train F1: 0.2330, Train Recall: 0.3021, Train Precision: 0.1897, Val Loss: 1.3393, Val Accuracy: 0.8148, Val F1: 0.2019, Val Recall: 0.3381, Val Precision: 0.1440, Best Threshold: 0.56\n",
            "Epoch 18/200, Loss: 0.0386, Train Accuracy: 0.8618, Train F1: 0.2355, Train Recall: 0.3073, Train Precision: 0.1909, Val Loss: 1.3503, Val Accuracy: 0.8107, Val F1: 0.2014, Val Recall: 0.3445, Val Precision: 0.1423, Best Threshold: 0.56\n",
            "Epoch 19/200, Loss: 0.0385, Train Accuracy: 0.8645, Train F1: 0.2384, Train Recall: 0.3061, Train Precision: 0.1952, Val Loss: 1.3365, Val Accuracy: 0.8134, Val F1: 0.1995, Val Recall: 0.3356, Val Precision: 0.1420, Best Threshold: 0.56\n",
            "Epoch 20/200, Loss: 0.0384, Train Accuracy: 0.8644, Train F1: 0.2441, Train Recall: 0.3158, Train Precision: 0.1989, Val Loss: 1.3362, Val Accuracy: 0.8151, Val F1: 0.2022, Val Recall: 0.3381, Val Precision: 0.1442, Best Threshold: 0.56\n",
            "Epoch 21/200, Loss: 0.0376, Train Accuracy: 0.8675, Train F1: 0.2471, Train Recall: 0.3139, Train Precision: 0.2037, Val Loss: 1.4034, Val Accuracy: 0.8231, Val F1: 0.2004, Val Recall: 0.3199, Val Precision: 0.1459, Best Threshold: 0.56\n",
            "Epoch 22/200, Loss: 0.0375, Train Accuracy: 0.8707, Train F1: 0.2504, Train Recall: 0.3117, Train Precision: 0.2092, Val Loss: 1.4068, Val Accuracy: 0.8252, Val F1: 0.1991, Val Recall: 0.3136, Val Precision: 0.1459, Best Threshold: 0.56\n",
            "Epoch 23/200, Loss: 0.0375, Train Accuracy: 0.8748, Train F1: 0.2500, Train Recall: 0.3012, Train Precision: 0.2137, Val Loss: 1.4180, Val Accuracy: 0.8315, Val F1: 0.2006, Val Recall: 0.3051, Val Precision: 0.1494, Best Threshold: 0.56\n",
            "Epoch 24/200, Loss: 0.0374, Train Accuracy: 0.8764, Train F1: 0.2560, Train Recall: 0.3069, Train Precision: 0.2195, Val Loss: 1.4100, Val Accuracy: 0.8311, Val F1: 0.1974, Val Recall: 0.2996, Val Precision: 0.1471, Best Threshold: 0.56\n",
            "Epoch 25/200, Loss: 0.0373, Train Accuracy: 0.8778, Train F1: 0.2550, Train Recall: 0.3019, Train Precision: 0.2208, Val Loss: 1.4264, Val Accuracy: 0.8330, Val F1: 0.1975, Val Recall: 0.2967, Val Precision: 0.1481, Best Threshold: 0.56\n",
            "Epoch 26/200, Loss: 0.0372, Train Accuracy: 0.8788, Train F1: 0.2562, Train Recall: 0.3014, Train Precision: 0.2228, Val Loss: 1.4223, Val Accuracy: 0.8353, Val F1: 0.1933, Val Recall: 0.2848, Val Precision: 0.1463, Best Threshold: 0.56\n",
            "Epoch 27/200, Loss: 0.0370, Train Accuracy: 0.8814, Train F1: 0.2599, Train Recall: 0.3006, Train Precision: 0.2289, Val Loss: 1.4483, Val Accuracy: 0.8383, Val F1: 0.1945, Val Recall: 0.2818, Val Precision: 0.1485, Best Threshold: 0.56\n",
            "Epoch 28/200, Loss: 0.0369, Train Accuracy: 0.8811, Train F1: 0.2617, Train Recall: 0.3041, Train Precision: 0.2298, Val Loss: 1.4480, Val Accuracy: 0.8375, Val F1: 0.1919, Val Recall: 0.2785, Val Precision: 0.1464, Best Threshold: 0.56\n",
            "Early stopping triggered after 28 epochs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/My Drive/Colab Notebooks/neural_net_model.pth\"  # Path where your model was saved\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKwUx0FuVtlY",
        "outputId": "75ae809b-968f-4eba-c4df-4932938731ba"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-1ffd2c3f3191>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (fc1): Linear(in_features=28, out_features=64, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=64, out_features=256, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (relu3): ReLU()\n",
              "  (dropout2): Dropout(p=0.3, inplace=False)\n",
              "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess X_test (if not done earlier)\n",
        "X_test_num_scaled = scaler.transform(X_test[numer])  # Only scale the numerical features\n",
        "X_test_scaled1 = pd.DataFrame(X_test_num_scaled, columns=numer, index=X_test.index)\n",
        "X_test_scaled = pd.concat([X_test_scaled1, X_test[dummy]], axis=1)\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "X_test_tensor = torch.tensor(X_test_scaled.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "ubpec1fYN0NM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor).squeeze()  # Raw logits\n",
        "\n",
        "# Convert logits to probabilities using sigmoid\n",
        "test_probabilities = torch.sigmoid(test_outputs).numpy()\n",
        "\n",
        "# Apply the best threshold for classification\n",
        "test_predictions = (test_probabilities > best_threshold).astype(int)"
      ],
      "metadata": {
        "id": "0NbhG-6SVqXP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = accuracy_score(y_test_tensor.numpy(), test_predictions)\n",
        "test_f1 = f1_score(y_test_tensor.numpy(), test_predictions)\n",
        "test_recall = recall_score(y_test_tensor.numpy(), test_predictions)\n",
        "test_precision = precision_score(y_test_tensor.numpy(), test_predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j53QkV4bVz45",
        "outputId": "49f7b350-ca9e-4258-c50c-97982e649e87"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8385\n",
            "Test F1 Score: 0.2015\n",
            "Test Recall: 0.2940\n",
            "Test Precision: 0.1532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers_iqr(df, columns, factor=1.5):\n",
        "    df_cleaned = df.copy()  # Make a copy of the DataFrame to avoid modifying original data\n",
        "\n",
        "    for column in columns:\n",
        "        if column in df_cleaned.columns:\n",
        "            Q1 = df_cleaned[column].quantile(0.25)  # 25th percentile\n",
        "            Q3 = df_cleaned[column].quantile(0.75)  # 75th percentile\n",
        "            IQR = Q3 - Q1\n",
        "\n",
        "            lower_bound = Q1 - factor * IQR\n",
        "            upper_bound = Q3 + factor * IQR\n",
        "\n",
        "            # Filter rows within the IQR bounds\n",
        "            df_cleaned[column] = df_cleaned[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "        else:\n",
        "            print(f\"Warning: Column '{column}' not found in DataFrame.\")\n",
        "\n",
        "    return df_cleaned\n",
        "\n"
      ],
      "metadata": {
        "id": "NkNuXAOSJfCP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "guXxQakUiv-u"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/testing_loan_data.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij4QqfkSkTdZ",
        "outputId": "0a8c1027-af0a-4e50-e53e-bcbe792d6e92"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-57f9f7af733e>:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/testing_loan_data.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "z7NtlklHkUnq",
        "outputId": "7eab7cf7-1fc8-4c81-82ae-09798fd91a11"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  member_id  loan_amnt        term int_rate emp_length  \\\n",
              "0  20000001   22419852      10000   36 months   22.15%    8 years   \n",
              "1  20000002   22349118       1400   36 months   18.24%    6 years   \n",
              "2  20000003   22398818       7000   36 months   12.49%    3 years   \n",
              "3  20000004   22419015      18000   60 months   16.29%    9 years   \n",
              "4  20000005   22388614      12000   36 months   12.99%  10+ years   \n",
              "\n",
              "  home_ownership  annual_inc desc             purpose  ...  inq_last_6mths  \\\n",
              "0           RENT     37000.0  NaN  debt_consolidation  ...               1   \n",
              "1           RENT     41000.0  NaN               other  ...               0   \n",
              "2           RENT     68900.0  NaN  debt_consolidation  ...               0   \n",
              "3       MORTGAGE     41000.0  NaN  debt_consolidation  ...               1   \n",
              "4       MORTGAGE     64000.0  NaN    home_improvement  ...               0   \n",
              "\n",
              "   mths_since_recent_inq  revol_util  total_bc_limit  \\\n",
              "0                    3.0      73.10%           16200   \n",
              "1                    9.0      11.50%            4000   \n",
              "2                   11.0      48.10%           11900   \n",
              "3                    0.0      38.10%            7600   \n",
              "4                    NaN      57.90%           21000   \n",
              "\n",
              "   mths_since_last_major_derog tot_hi_cred_lim  tot_cur_bal  \\\n",
              "0                          NaN    14877.170280        36809   \n",
              "1                          NaN     4097.304770        19536   \n",
              "2                         80.0    12688.495160       241465   \n",
              "3                         73.0     7908.799817       179757   \n",
              "4                          NaN    19378.561060        31953   \n",
              "\n",
              "   application_approved_flag  internal_score  bad_flag  \n",
              "0                          1             131       NaN  \n",
              "1                          1              19       NaN  \n",
              "2                          1              92       NaN  \n",
              "3                          1             235       NaN  \n",
              "4                          1             157       NaN  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77e7c06c-8710-41f3-b819-7c1d0f8ea2f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>member_id</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>term</th>\n",
              "      <th>int_rate</th>\n",
              "      <th>emp_length</th>\n",
              "      <th>home_ownership</th>\n",
              "      <th>annual_inc</th>\n",
              "      <th>desc</th>\n",
              "      <th>purpose</th>\n",
              "      <th>...</th>\n",
              "      <th>inq_last_6mths</th>\n",
              "      <th>mths_since_recent_inq</th>\n",
              "      <th>revol_util</th>\n",
              "      <th>total_bc_limit</th>\n",
              "      <th>mths_since_last_major_derog</th>\n",
              "      <th>tot_hi_cred_lim</th>\n",
              "      <th>tot_cur_bal</th>\n",
              "      <th>application_approved_flag</th>\n",
              "      <th>internal_score</th>\n",
              "      <th>bad_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20000001</td>\n",
              "      <td>22419852</td>\n",
              "      <td>10000</td>\n",
              "      <td>36 months</td>\n",
              "      <td>22.15%</td>\n",
              "      <td>8 years</td>\n",
              "      <td>RENT</td>\n",
              "      <td>37000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>73.10%</td>\n",
              "      <td>16200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14877.170280</td>\n",
              "      <td>36809</td>\n",
              "      <td>1</td>\n",
              "      <td>131</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20000002</td>\n",
              "      <td>22349118</td>\n",
              "      <td>1400</td>\n",
              "      <td>36 months</td>\n",
              "      <td>18.24%</td>\n",
              "      <td>6 years</td>\n",
              "      <td>RENT</td>\n",
              "      <td>41000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.50%</td>\n",
              "      <td>4000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4097.304770</td>\n",
              "      <td>19536</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20000003</td>\n",
              "      <td>22398818</td>\n",
              "      <td>7000</td>\n",
              "      <td>36 months</td>\n",
              "      <td>12.49%</td>\n",
              "      <td>3 years</td>\n",
              "      <td>RENT</td>\n",
              "      <td>68900.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>48.10%</td>\n",
              "      <td>11900</td>\n",
              "      <td>80.0</td>\n",
              "      <td>12688.495160</td>\n",
              "      <td>241465</td>\n",
              "      <td>1</td>\n",
              "      <td>92</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20000004</td>\n",
              "      <td>22419015</td>\n",
              "      <td>18000</td>\n",
              "      <td>60 months</td>\n",
              "      <td>16.29%</td>\n",
              "      <td>9 years</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>41000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.10%</td>\n",
              "      <td>7600</td>\n",
              "      <td>73.0</td>\n",
              "      <td>7908.799817</td>\n",
              "      <td>179757</td>\n",
              "      <td>1</td>\n",
              "      <td>235</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20000005</td>\n",
              "      <td>22388614</td>\n",
              "      <td>12000</td>\n",
              "      <td>36 months</td>\n",
              "      <td>12.99%</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>64000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>home_improvement</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>57.90%</td>\n",
              "      <td>21000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19378.561060</td>\n",
              "      <td>31953</td>\n",
              "      <td>1</td>\n",
              "      <td>157</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77e7c06c-8710-41f3-b819-7c1d0f8ea2f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77e7c06c-8710-41f3-b819-7c1d0f8ea2f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77e7c06c-8710-41f3-b819-7c1d0f8ea2f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e05200a3-4c26-4d0d-bc60-2c6032d585e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e05200a3-4c26-4d0d-bc60-2c6032d585e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e05200a3-4c26-4d0d-bc60-2c6032d585e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "miscol = ['id', 'application_approved_flag', 'tot_hi_cred_lim', 'revol_util', 'loan_amnt', 'bc_util', 'desc', 'member_id', 'mths_since_last_major_derog']  ##drop useless columns\n",
        "test_data.drop(miscol, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "nyBHuXhD7uxj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['term'] = test_data['term'].str.extract('(\\d+)').astype(float)\n",
        "test_data['emp_length'] = test_data['emp_length'].str.extract('(\\d+)').astype(float)\n",
        "test_data['emp_length'] = test_data['emp_length'].fillna(0)  # Assume missing values as 0 (less than a year)"
      ],
      "metadata": {
        "id": "7UDNeKto8vwx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_columns = ['int_rate']\n",
        "for col in percentage_columns:\n",
        "    if col in test_data.columns and test_data[col].dtype == 'object':\n",
        "        test_data[col] = test_data[col].str.replace('%', '').astype(float) / 100"
      ],
      "metadata": {
        "id": "0bqLQPO09DxS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['mths_since_recent_inq'] = test_data['mths_since_recent_inq'].fillna(0)"
      ],
      "metadata": {
        "id": "fM8JwzQV-II-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_impute = [\n",
        "       'percent_bc_gt_75',\n",
        "      'total_bc_limit',  'tot_cur_bal'\n",
        "]\n",
        "\n",
        "# Replace missing values with the median for each column\n",
        "for col in columns_to_impute:\n",
        "    test_data[col] = test_data[col].fillna(test_data[col].median())"
      ],
      "metadata": {
        "id": "jNt4QvE-9Mxh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['home_ownership'] = test_data['home_ownership'].replace(['OTHER', 'NONE'], 'OTHER')"
      ],
      "metadata": {
        "id": "8M5Fjqhy9ucl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['purpose', 'home_ownership']\n",
        "test_data_encoded = pd.get_dummies(test_data, columns=categorical_columns, drop_first=False, dtype=int)"
      ],
      "metadata": {
        "id": "PQYKf0cM-eRc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to clean\n",
        "columns_to_check = [ 'term', 'int_rate', 'emp_length', 'annual_inc', 'percent_bc_gt_75',\n",
        "        'dti', 'inq_last_6mths', 'mths_since_recent_inq',\n",
        "       'total_bc_limit', 'tot_cur_bal', 'internal_score']\n",
        "\n",
        "\n",
        "# Remove outliers\n",
        "cleaned_data = remove_outliers_iqr(test_data_encoded, columns_to_check)"
      ],
      "metadata": {
        "id": "Jav4YGFf-xsh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = cleaned_data.columns.difference(numer)"
      ],
      "metadata": {
        "id": "mphTVAoB_uEO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data_num_scaled = scaler.transform(cleaned_data[numer])\n",
        "cleaned_data_scaled1 = pd.DataFrame(cleaned_data_num_scaled, columns=numer, index=cleaned_data.index)\n",
        "cleaned_data_scaled = pd.concat([cleaned_data_scaled1, cleaned_data[dummy]], axis=1)"
      ],
      "metadata": {
        "id": "6E7vEnIq-_l5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert test data to PyTorch tensors\n",
        "X_test_tensor = torch.tensor(cleaned_data_scaled.values, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoader for batch processing (optional)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor), batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "QkXD6eiN-58v"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FHavjAxM-xIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs in test_loader:\n",
        "        inputs = inputs[0]  # Extract inputs from TensorDataset\n",
        "        outputs = model(inputs).squeeze()  # Forward pass\n",
        "        probabilities = torch.sigmoid(outputs)  # Convert logits to probabilities\n",
        "\n",
        "        # Apply the best threshold\n",
        "        predictions = (probabilities > 0.56).int()\n",
        "\n",
        "        all_predictions.extend(predictions.tolist())\n",
        "\n",
        "# ===========================\n",
        "# 4. Fill Target Column\n",
        "# ===========================\n",
        "# Insert predictions into the test dataset\n",
        "test_data[\"bad_flag\"] = all_predictions  # Replace 'target' with the actual column name\n",
        "\n",
        "# Save the updated test dataset\n",
        "test_data.to_csv(\"/content/drive/My Drive/Colab Notebooks/test_predictions_filled.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyRrSt-fd5U4",
        "outputId": "191d6d99-71f3-44f8-dbb9-18a8de8ac7b6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3zPzvumnjWtL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}